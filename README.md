# ü´Å Pneumonia Detection from Chest X-Ray Images

This project develops a deep learning CNN model to classify chest X-ray images into 2 classes: **NORMAL** (healthy lungs) and **PNEUMONIA** (pneumonia-affected lungs).

## üéØ Project Objectives

- ‚úÖ Build and train an efficient baseline CNN model
- ‚úÖ Achieve high accuracy in pneumonia detection
- ‚úÖ Implement Grad-CAM to explain model decisions
- ‚úÖ Perform in-depth analysis of Precision, Recall, and F1-Score metrics
- ‚úÖ Handle data imbalance using Class Weights

## üìä Dataset

### Data Source
- **Dataset**: [Kaggle Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
- **Total Images**: ~5,800 X-ray images
- **Format**: JPEG grayscale, 224√ó224 pixels size
- **Classes**: 2 classes (NORMAL vs PNEUMONIA)
- **Dataset Author**: Paul Mooney

### Data Distribution

#### Original Dataset (Before Train/Val Split)

| Split/Category | Train | Val | Test | **Total** |
|:---|:---|:---|:---|:---|
| **NORMAL** | 1,341 | 8 | 234 | **1,583** |
| **PNEUMONIA** | 3,875 | 8 | 390 | **4,273** |
| **Total** | **5,216** | **16** | **624** | **5,856** |

#### After Train/Val Re-split (Final Distribution)

| Split/Category | Train | Val | Test | **Total** |
|:---|:---|:---|:---|:---|
| **NORMAL** | 1,214 | 135 | 234 | **1,583** |
| **PNEUMONIA** | 3,494 | 389 | 390 | **4,273** |
| **Total** | **4,708** | **524** | **624** | **5,856** |

**Key Changes:**
- ‚úÖ Increased validation set from 16 to 524 images for better model evaluation
- ‚úÖ Maintained test set at 624 images for consistent performance assessment
- ‚úÖ Redistributed training set to 4,708 images with balanced representation
- ‚úÖ Better validation set size helps detect overfitting more reliably

![Data Distribution](asset/phan_bo.png)

### Handling Data Imbalance

Using **Class Weights** to balance the 2 classes:
- **NORMAL (Class 0)**: 1.939
- **PNEUMONIA (Class 1)**: 0.674

This method automatically balances the influence of each class during training without losing data.

## üß† Model Architecture

### Baseline CNN
The model consists of:

**4 Conv Blocks** (each block):
- 2 √ó Conv2D layers (32 ‚Üí 64 ‚Üí 128 ‚Üí 256 filters)
- BatchNormalization (output normalization)
- MaxPooling2D (2√ó2) - dimension reduction
- Dropout (0.25) - prevent overfitting

**Dense Layers**:
- Flatten - convert from 2D to 1D
- Dense(512, relu) + BatchNorm + Dropout(0.5)
- Dense(256, relu) + BatchNorm + Dropout(0.5)
- Dense(1, sigmoid) ‚Üí Output (0 = NORMAL, 1 = PNEUMONIA)

### Model Parameters

| Attribute | Value |
|-----------|-------|
| **Input Shape** | 224 √ó 224 √ó 1 (grayscale) |
| **Total Parameters** | 27,000,801 |
| **Batch Size** | 32 |
| **Epochs Trained** | 42 |
| **Optimizer** | Adam (learning rate = 0.001) |
| **Loss Function** | Binary Crossentropy |
| **Early Stopping** | Yes (patience=10 on val_auc) |
| **Regularization** | Dropout + BatchNormalization |

## üìà Training Results & Evaluation

### Performance on Test Set

| Metric | Value |
|--------|-------|
| **Accuracy** | 85.74% |
| **Precision** | 82.65% |
| **Recall** | 97.69% |
| **AUC** | 0.9516 |
| **F1-Score** | 0.8954 |

### Confusion Matrix

![Confusion Matrix](asset/confusion_matrix.png)

Confusion matrix shows:
- **True Negatives (TN)**: Number of NORMAL images correctly predicted
- **True Positives (TP)**: Number of PNEUMONIA images correctly predicted
- **False Positives (FP)**: Number of NORMAL images incorrectly predicted as PNEUMONIA
- **False Negatives (FN)**: Number of PNEUMONIA images incorrectly predicted as NORMAL (very few - only 2.31%)

### Detailed Metric Explanations

**üìä Accuracy (Overall Accuracy)**
- Ratio of correct predictions to total predictions
- **85.74%** = Model correctly predicts 85.74% of test cases

**‚úÖ Precision (Positive Predictive Value)**
- Among images the model predicts as "PNEUMONIA", **82.65%** truly have pneumonia
- **Meaning**: When the model alerts "pneumonia", you can trust it 82.65%
- **Application**: Avoids excessive false alarms

**üîç Recall (Sensitivity)**
- Among images truly with "PNEUMONIA", the model detects **97.69%**
- **Meaning**: The model rarely misses actual cases (only misses ~2.31%)
- **Important in Healthcare**: High recall reduces the risk of missing diseases
- **Trade-off**: To achieve high recall, the model must be more "lenient", resulting in some false alerts (lower precision)

**üéØ AUC (Area Under Curve)**
- **0.9516** indicates the model has excellent ability to distinguish between 2 classes
- Values closer to 1.0 are better

**‚öñÔ∏è F1-Score**
- **0.8954** is the harmonic mean of Precision and Recall
- Provides a balanced assessment of model performance
- Suitable when considering both metrics equally

## üìà ROC Curve & AUC Analysis

### ROC Curve (Receiver Operating Characteristic)
The ROC curve displays the balance between **True Positive Rate (Recall)** and **False Positive Rate** as the prediction threshold changes.

![ROC Curve - AUC = 0.9516](asset/ROC_curve.png)

### ROC Curve Explanation

**üìä AUC (Area Under Curve) = 0.9516**
- **Meaning**: Model has a **95.16%** probability of ranking a PNEUMONIA image higher than a NORMAL image
- **Excellent Value**: 
  - 0.5 = Random (no better than chance)
  - 0.7 - 0.8 = Good
  - 0.8 - 0.9 = Very Good
  - 0.9 - 1.0 = Excellent ‚úì

**üéØ Optimal Point**
- Optimal point is marked on the curve (optimal threshold ‚âà 0.946)
- At this point, the model achieves the best balance between:
  - TPR (True Positive Rate) = High Recall
  - FPR (False Positive Rate) = Low False Alerts

**üìç Diagonal Line (Random Classifier)**
- The red dashed diagonal represents a random classifier (AUC = 0.5)
- Our model lies **well above the diagonal** ‚úì ‚Üí Superior performance

### Healthcare Application
- **High AUC** ‚Üí Model distinguishes NORMAL and PNEUMONIA excellently
- **Disregards False Positive Rate** ‚Üí Can be used when high recall is needed
- **Suitable for imbalanced data** ‚Üí Not affected by class imbalance

## üì¶ Training Techniques

### Early Stopping & Learning Rate Reduction
- **Early Stopping**: Stop training when `val_auc` doesn't improve for 10 consecutive epochs
- **ReduceLROnPlateau**: Reduce learning rate when loss plateaus
- **ModelCheckpoint**: Automatically save best model based on highest val_auc

### Data Augmentation
- Rotation ¬±10 degrees
- Width/Height shift: ¬±10%
- Shear: ¬±10%
- Zoom: ¬±20%
- Horizontal flip: Disabled (don't flip, medical X-rays must maintain orientation)

This technique helps the model generalize better and prevents overfitting on small training datasets.

## üîç Grad-CAM: Explaining Model Decisions

**Grad-CAM** (Gradient-weighted Class Activation Mapping) is a technique to visualize regions of an image that the model focuses on to make decisions.

### Significance
- Helps understand where the model "looks"
- Identifies important medical indicators
- Increases confidence when applying model in practice

### Results
The `Grad_CAM.ipynb` notebook displays:
- Heatmap of important regions on PNEUMONIA images
- Helps doctors confirm model decisions
- Model focuses on areas showing disease signs

![Example Prediction](asset/grad-cam.png)

## üìä Precision vs Recall Analysis

### Trade-off Between 2 Metrics

**Precision ‚Üë (High Accuracy)**
- Model is "conservative" ‚Üí predicts PNEUMONIA only when very confident
- Few false alarms ‚úì
- But misses many disease cases ‚úó

**Recall ‚Üë (High Sensitivity)**
- Model is "lenient" ‚Üí predicts PNEUMONIA if there's possibility
- Detects most disease cases ‚úì
- But produces many false alarms ‚úó

### Choice in Healthcare

**In disease detection applications, Recall is prioritized over Precision**

Why?
- **Cost of missing disease**: Very high (patient doesn't receive treatment)
- **Cost of false alert**: Lower (patient can get additional tests)

**This model achieves:**
- Recall = 97.69% ‚úì (Detects nearly all disease cases)
- Precision = 82.65% ‚úì (Controlled false alerts)
- F1-Score = 0.8954 ‚úì (Good balance)


## üöÄ Quick Start Guide

### 1Ô∏è‚É£ Environment Setup

```bash
# Install dependencies
pip install -r requirements.txt
```

### 2Ô∏è‚É£ Run Web Application

```bash
# Start Streamlit app
streamlit run app.py
```
The application will open at `http://localhost:8501`

### 3Ô∏è‚É£ Explore Notebooks

Open Jupyter Notebooks in the `notebooks/` folder:
- **`notebook.ipynb`** - Train CNN model from scratch
- **`Grad_CAM.ipynb`** - Visualize Grad-CAM (explain decisions)
- **`AUC.ipynb`** - Analyze ROC Curve & AUC
- **`pre_rec.ipynb`** - Analyze Precision vs Recall
- **`push_model2hf.ipynb`** - Push model to Hugging Face

## üí° Key Points & Conclusion

### 1. Model Performance
‚úÖ **Very High Recall (97.69%)** ‚Üí Detects nearly all disease cases  
‚úÖ **Good Precision (82.65%)** ‚Üí Controlled false alerts  
‚úÖ **Superior AUC (0.9516)** ‚Üí Excellent class discrimination ability  
‚úÖ **Balanced sensitivity & specificity** ‚Üí Suitable for healthcare

### 2. Handling Data Imbalance
‚úÖ **Class Weights effective** ‚Üí Automatically balances 2 classes  
‚úÖ **Preserves data** ‚Üí No information loss  
‚úÖ **Suitable for healthcare context** ‚Üí Uses all clinical cases

### 3. Regularization & Overfitting Prevention
‚úÖ **Dropout + BatchNormalization** ‚Üí Prevents overfitting  
‚úÖ **Early Stopping** ‚Üí Stops at optimal point (epoch 42)  
‚úÖ **Data Augmentation** ‚Üí Improves generalization  

### 4. Model Explainability
‚úÖ **Grad-CAM visualization** ‚Üí Explains model decisions  
‚úÖ **Precision-Recall analysis** ‚Üí Understands trade-offs  
‚úÖ **Transparency** ‚Üí Trust model in healthcare

## üîÑ Project Workflow

**Data Preparation** ‚Üí **Model Building** ‚Üí **Training** ‚Üí **Evaluation** ‚Üí **Analysis** ‚Üí **Deployment**

1. **Data Preparation** (notebook.ipynb)
   - Load Kaggle dataset
   - Split train/val 9:1
   - Analyze and visualize

2. **Building & Training** (notebook.ipynb)
   - Design CNN architecture
   - Compile with healthcare metrics
   - Training with class weights

3. **Evaluation & Analysis** (notebook.ipynb, Grad_CAM.ipynb, pre_rec.ipynb)
   - Test set evaluation
   - Confusion matrix
   - Grad-CAM visualization
   - Precision/Recall trade-off

## üìö References

### Dataset
- [Kaggle: Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
- [Original Research Paper](https://www.cell.com/cell/fulltext/S0092-8674(18)30154-5)

### CNN & Deep Learning
- [Convolutional Neural Networks: Architectures, Mechanisms, and Applications](https://arxiv.org/abs/2010.07468)
- [A Guide to Convolutional Neural Networks](https://arxiv.org/abs/1808.04752)
- [VGG Networks: Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)

### Model Interpretability
- [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://arxiv.org/abs/1610.02055)
- [Interpretable Explanations of Black Boxes by Meaningful Perturbation](https://arxiv.org/abs/1506.02390)

### Framework & Tools
- [TensorFlow/Keras Documentation](https://www.tensorflow.org/)
- [Keras API Reference - Class Weights](https://keras.io/api/models/sequential/#fit)
- [Scikit-learn: Machine Learning Library](https://scikit-learn.org/)

## ‚ö†Ô∏è Important Disclaimer

### üî¥ Disclaimer
This model is developed for **educational and research purposes only**.  
**Should NOT be used directly for real medical diagnosis**.  
Any medical decision must be confirmed by trained medical professionals.

### üìå Model Limitations
- Only trained on Kaggle dataset
- Fixed image size 224√ó224 pixels
- Only binary classification (NORMAL vs PNEUMONIA)
- May not generalize well to data from other hospitals

### ‚úÖ Safe Usage Guidelines
- **Use as a decision support tool**, not a replacement for doctors
- **Always combine** with expert clinical diagnosis
- **Check Confidence Score** before application
- **Specially focus on** False Negatives (missed diseases)

### üè• Usage Recommendations
1. Treat model as a "second opinion" tool
2. When model predicts "NORMAL" with Confidence < 80% ‚Üí Recommend re-examination
3. When model predicts "PNEUMONIA" ‚Üí Require doctor confirmation
4. Record all results in patient records

## üìù Project Information

- **Creation Date**: November 18, 2025
- **Model Timestamp**: 20251118_091549
- **Purpose**: Education & Research
- **Dataset**: Kaggle Chest X-Ray Images (Pneumonia)
- **Framework**: TensorFlow/Keras
- **GPU**: NVIDIA P100 (if available)

---

**"Prevention is better than cure" - This model is a support tool, not a doctor replacement** üè•
